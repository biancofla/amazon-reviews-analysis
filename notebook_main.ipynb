{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import matplotlib.pyplot as plt\n",
    "import databricks.koalas as ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_db = 'mongodb+srv://<username>:<password>@bigdata.toqh2.mongodb.net'\n",
    "spark_connector_uri = 'org.mongodb.spark:mongo-spark-connector_2.11:2.2.7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession object.\n",
    "session = SparkSession.builder \\\n",
    "    .master('local') \\\n",
    "    .config('spark.mongodb.input.uri', uri_db) \\\n",
    "    .config('spark.jars.packages', spark_connector_uri) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Get context from SparkSession object.\n",
    "context = session.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from MongoDB and return two DataFrame objects, one\n",
    "# for each collection contained in database.\n",
    "df_reviews = session.read \\\n",
    "    .format('com.mongodb.spark.sql.DefaultSource') \\\n",
    "    .option('database', 'test') \\\n",
    "    .option('collection', 'reviews') \\\n",
    "    .load()\n",
    "df_meta = session.read \\\n",
    "    .format('com.mongodb.spark.sql.DefaultSource') \\\n",
    "    .option('database', 'test') \\\n",
    "    .option('collection', 'meta') \\\n",
    "    .load()\n",
    "\n",
    "# Drop MongoDB _id column in order to avoid error at runtime.\n",
    "df_reviews = df_reviews.drop('_id')\n",
    "df_meta = df_meta.drop('_id')\n",
    "\n",
    "# Print collections schemas.\n",
    "df_reviews.printSchema()\n",
    "df_meta.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two Koalas DataFrame from the Spark DataFrame objects.\n",
    "kdf_reviews = ks.DataFrame(df_reviews)\n",
    "kdf_meta = ks.DataFrame(df_meta)\n",
    "\n",
    "# Extract sports and outdoors data from salesRank struct.\n",
    "array_ranks = df_meta.select('salesRank.Sports &amp; Outdoors').to_koalas()\n",
    "\n",
    "# Allow merge from different DataFrame objects.\n",
    "ks.set_option('compute.ops_on_diff_frames', True)\n",
    "\n",
    "# Assign a new column with the array_ranks data extracted above.\n",
    "kdf_meta['sales_rank_sports_etc'] = array_ranks\n",
    "\n",
    "# Compute join on asin attribute.\n",
    "kdf_merge = kdf_reviews.merge(kdf_meta, on='asin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query #1\n",
    "kdf_1 = kdf_reviews \\\n",
    "    .groupby('asin') \\\n",
    "    .size().alias('reviews_count_product') \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .reset_index()\n",
    "\n",
    "kdf_1.head(100).to_csv(path='./to_csv/kdf_1.csv', num_files=1)\n",
    "\n",
    "print(\"# I 100 prodotti con il maggior numero di recensioni #\")\n",
    "kdf_1.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Query #2\n",
    "kdf_2 = kdf_reviews \\\n",
    "    .groupby('reviewerID') \\\n",
    "    .size().alias('reviews_count_reviewer') \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .reset_index()\n",
    "\n",
    "kdf_2.head(100).to_csv(path='./to_csv/kdf_2.csv', num_files=1)\n",
    "\n",
    "print(\"# I 100 reviewer che hanno effettuato il maggior numero di recensioni #\")\n",
    "kdf_2.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query #3\n",
    "kdf_3 =  kdf_merge \\\n",
    "    [kdf_merge.brand != ''] \\\n",
    "    .dropna(subset=['brand']) \\\n",
    "    .groupby('brand') \\\n",
    "    .size().alias('reviews_count_brand') \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .reset_index()\n",
    "\n",
    "kdf_3.head(50).to_csv(path='./to_csv/kdf_3.csv', num_files=1)\n",
    "\n",
    "print(\"# Le 50 marche i cui prodotti sono stati maggiormente recensiti #\")\n",
    "kdf_3.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query #4\n",
    "kdf_4 =  kdf_meta \\\n",
    "     .dropna(subset=['brand', 'price']) \\\n",
    "     .groupby('brand') \\\n",
    "     ['price'] \\\n",
    "     .mean().alias('price_mean') \\\n",
    "     .sort_values(ascending=False) \\\n",
    "     .reset_index()\n",
    "\n",
    "kdf_4.head(50).to_csv(path='./to_csv/kdf_4.csv', num_files=1)\n",
    "\n",
    "print(\"# Le 50 marche i cui prodotti hanno un prezzo medio maggiore #\")\n",
    "kdf_4.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Query #5\n",
    "kdf_5 = kdf_reviews \\\n",
    "    .groupby('asin') \\\n",
    "    ['overall'] \\\n",
    "    .mean().alias('overall_mean_product') \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .reset_index()\n",
    "\n",
    "kdf_5 = kdf_5 \\\n",
    "    .merge(kdf_1, on='asin') \\\n",
    "    .sort_values(by=['overall_mean_product', 'reviews_count_product'], ascending=False)\n",
    "\n",
    "kdf_5.head(100).to_csv(path='./to_csv/kdf_5.csv', num_files=1)\n",
    "\n",
    "print(\"# I 100 prodotti con le migliori recensioni #\")\n",
    "kdf_5.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query #6\n",
    "kdf_6 = kdf_merge \\\n",
    "    [kdf_merge.brand != ''] \\\n",
    "    .dropna(subset=['brand']) \\\n",
    "    .groupby('brand') \\\n",
    "    ['overall'] \\\n",
    "    .mean().alias('overall_mean_brand') \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .reset_index()\n",
    "\n",
    "kdf_6 = kdf_6 \\\n",
    "    .merge(kdf_3, on='brand') \\\n",
    "    .sort_values(by=['overall_mean_brand', 'reviews_count_brand'], ascending=False)\n",
    "\n",
    "kdf_6.head(100).to_csv(path='./to_csv/kdf_6.csv', num_files=1)\n",
    "\n",
    "print(\"# Le 100 marche con le migliori recensioni #\")\n",
    "kdf_6.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query #7 - #8\n",
    "def get_helpful_rate(x):\n",
    "    if x[1] == 0:\n",
    "        return 0\n",
    "    return (x[0]/x[1]) * 100\n",
    "\n",
    "kdf_reviews['helpful_rate'] = kdf_reviews['helpful'].map(lambda x: get_helpful_rate(x))\n",
    "kdf_reviews['helpful_pos'] = kdf_reviews['helpful'].map(lambda x: x[0])\n",
    "\n",
    "kdf_reviews = kdf_reviews[kdf_reviews.helpful_pos != 0]\n",
    "\n",
    "kdf_mean = kdf_reviews \\\n",
    "    [['reviewerID', 'helpful_rate']] \\\n",
    "    .groupby('reviewerID') \\\n",
    "    .mean() \\\n",
    "    .sort_values(by=['helpful_rate'], ascending=False) \\\n",
    "    .reset_index()\n",
    "\n",
    "kdf_sum = kdf_reviews \\\n",
    "    [['reviewerID', 'helpful_pos']] \\\n",
    "    .groupby('reviewerID') \\\n",
    "    .sum() \\\n",
    "    .sort_values(by=['helpful_pos'], ascending=False) \\\n",
    "    .reset_index()\n",
    "\n",
    "kdf_7_8 = kdf_mean \\\n",
    "    .merge(kdf_sum, on='reviewerID') \\\n",
    "    .sort_values(by=['helpful_rate', 'helpful_pos'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query #7\n",
    "kdf_7 = kdf_7_8.head(100)\n",
    "\n",
    "kdf_7.to_csv(path='./to_csv/kdf_7.csv', num_files=1)\n",
    "\n",
    "print(\"# I 100 reviewer che hanno effettuato recensioni con la maggiore utilità media #\")\n",
    "kdf_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query #8\n",
    "# BUG: Poor performance on reverse indexing.\n",
    "kdf_8 = kdf_7_8[-1:-101: -1]\n",
    "\n",
    "kdf_8.to_csv(path='./to_csv/kdf_8.csv', num_files=1)\n",
    "\n",
    "print(\"# I 100 reviewer che hanno effettuato recensioni con la minore utilità media #\")\n",
    "kdf_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query #9\n",
    "kdf_9 = kdf_meta \\\n",
    "    .dropna(subset=['sales_rank_sports_etc']) \\\n",
    "    .sort_values(by=['sales_rank_sports_etc'], ascending=True) \\\n",
    "    [['asin', 'sales_rank_sports_etc']]\n",
    "\n",
    "kdf_9.head(100).to_csv(path='./to_csv/kdf_9.csv', num_files=1)\n",
    "\n",
    "print('# I 100 prodotti con il migliore ranking nelle vendite #')\n",
    "kdf_9.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query #10\n",
    "kdf_10 = kdf_meta \\\n",
    "    [kdf_meta.brand != ''] \\\n",
    "    .dropna(subset=['brand', 'sales_rank_sports_etc']) \\\n",
    "    [['brand', 'sales_rank_sports_etc']] \\\n",
    "    .groupby('brand') \\\n",
    "    .mean() \\\n",
    "    .sort_values(by=['sales_rank_sports_etc'], ascending=True) \\\n",
    "    .reset_index()\n",
    "\n",
    "kdf_10.head(50).to_csv(path='./to_csv/kdf_10.csv', num_files=1)\n",
    "\n",
    "print('# Le 50 marche i cui prodotti hanno il ranking medio migliore #')\n",
    "kdf_10.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdf_merge['helpful_rate'] = kdf_reviews['helpful_rate']\n",
    "\n",
    "# Drop useless columns.\n",
    "kdf_subset = kdf_merge.drop(['helpful', 'reviewerID', 'reviewerName', \\\n",
    "    'reviewTime', 'imUrl', 'related', 'salesRank', 'categories'], axis=1)\n",
    "\n",
    "# Drop null values on critical columns.\n",
    "kdf_subset = kdf_subset \\\n",
    "    .dropna(subset=['helpful_rate', 'price', 'title', 'description', \\\n",
    "        'brand', 'sales_rank_sports_etc'])\n",
    "\n",
    "# Join with kdf_1 in order to obtain reviews_count_product column.\n",
    "kdf_subset = kdf_subset.merge(kdf_1, on='asin')\n",
    "# Join with kdf_5 in order to obtain overall_mean_product column.\n",
    "# N.B. The review_count_product attribute is dropped because of\n",
    "# duplication.\n",
    "kdf_subset = kdf_subset.merge(kdf_5.drop('reviews_count_product'), on='asin')\n",
    "\n",
    "brand_categorical = {}\n",
    "index_categorical = 0\n",
    "def map_brand_to_categorical(brand):\n",
    "    '''\n",
    "        Map brand's name to categorical.\n",
    "\n",
    "        Args:\n",
    "            brand (string): brand's name.\n",
    "        Return:\n",
    "            int: categorical value.\n",
    "    '''\n",
    "    global brand_categorical\n",
    "    global index_categorical\n",
    "\n",
    "    if brand not in brand_categorical.keys():\n",
    "        brand_categorical[brand] = index_categorical\n",
    "        index_categorical += 1\n",
    "\n",
    "    return brand_categorical[brand]\n",
    "\n",
    "# Create new columns:\n",
    "# * brand_cat: brand's name in form of categorical;\n",
    "# * product_title_len: product's title length;\n",
    "# * product_description_len: product's description length;\n",
    "# * review_summary_len: review's title length;\n",
    "# * review_text_len: review's text length.\n",
    "kdf_subset['brand_cat'] = kdf_subset['brand'].map(map_brand_to_categorical)\n",
    "kdf_subset['product_description_len'] = kdf_subset['description'].map(len)\n",
    "kdf_subset['product_title_len'] = kdf_subset['title'].map(len)\n",
    "kdf_subset['review_text_len'] = kdf_subset['reviewText'].map(len)\n",
    "kdf_subset['review_summary_len'] = kdf_subset['summary'].map(len)\n",
    "\n",
    "# Drop non numeric column.\n",
    "kdf_subset = kdf_subset.drop(['asin', 'brand', 'description', 'title', \\\n",
    "    'reviewText', 'summary'], axis=1)\n",
    "\n",
    "kdf_subset.to_csv(path='./to_csv/kdf_subset.csv', num_files=1)\n",
    "\n",
    "# Compute correlation matrix.\n",
    "corr_mat = kdf_subset.corr().to_numpy()\n",
    "\n",
    "# Plot correlation matrix.\n",
    "plt.figure(1)\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(corr_mat, cmap='coolwarm')\n",
    "\n",
    "ax.set_xticks(range(len(kdf_subset.columns)))\n",
    "ax.set_yticks(range(len(kdf_subset.columns)))\n",
    "ax.set_xticklabels(kdf_subset.columns)\n",
    "ax.set_yticklabels(kdf_subset.columns)\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha='right', \\\n",
    "    rotation_mode='anchor')\n",
    "\n",
    "for i in range(len(kdf_subset.columns)):\n",
    "    for j in range(len(kdf_subset.columns)):\n",
    "        text = ax.text(j, i, '{:0.2f}'.format(corr_mat[i, j]), \\\n",
    "            ha='center', va='center', color='w', size='3')\n",
    "\n",
    "ax.set_title(\"Correlation matrix\")\n",
    "fig.colorbar(im, orientation='vertical')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbasecondad54da413211c4fdb9c2b9bc2046d2ac1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}